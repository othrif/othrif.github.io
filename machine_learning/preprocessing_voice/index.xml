<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine_learning - Othmane Rifki</title>
    <link>https://othrif.github.io/machine_learning/preprocessing_voice/index.xml</link>
    <description></description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 12 Apr 2020 14:41:32 +0200</lastBuildDate>
    
        <atom:link href="https://othrif.github.io/machine_learning/preprocessing_voice/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Audio i/o devices</title>
      <link>https://othrif.github.io/machine_learning/preprocessing_voice/devices_connected.html</link>
      <pubDate>Sun, 12 Apr 2020 14:41:32 +0200</pubDate>
      
      <guid>https://othrif.github.io/machine_learning/preprocessing_voice/devices_connected.html</guid>
      <description>import sounddevice as sd sd.query_devices()  0 LG ULTRAWIDE, Core Audio (0 in, 2 out) 1 Jabra Link 370, Core Audio (0 in, 2 out) 2 Jabra Link 370, Core Audio (1 in, 0 out) &amp;gt; 3 MacBook Pro Microphone, Core Audio (1 in, 0 out) &amp;lt; 4 MacBook Pro Speakers, Core Audio (0 in, 2 out)  </description>
    </item>
    
    <item>
      <title>Convert between audio formats</title>
      <link>https://othrif.github.io/machine_learning/preprocessing_voice/convert_sound_format.html</link>
      <pubDate>Sun, 12 Apr 2020 14:41:32 +0200</pubDate>
      
      <guid>https://othrif.github.io/machine_learning/preprocessing_voice/convert_sound_format.html</guid>
      <description>Convert in CLI sox new.wav new.mp3 Convert to a different bit depth and sampling rate ffmpeg -i input.wav -ac 1 -ar 16000 -sample_fmt s16 output.wav Available bit depth optons:
ffmpeg -sample_fmts Convert Numpy to WAV with wavio wavio.write writes a numpy array to a WAV file, optionally using a specified sample width.
Create a numpy array of 16-bit sine wave import numpy as np frequency = 440 # Our played note will be 440 Hz fs = 44100 # 44100 samples per second seconds = 3 # Note duration of 3 seconds t = np.</description>
    </item>
    
    <item>
      <title>Convert mov to gif</title>
      <link>https://othrif.github.io/machine_learning/preprocessing_voice/convert_mov_gif.html</link>
      <pubDate>Sun, 12 Apr 2020 14:41:32 +0200</pubDate>
      
      <guid>https://othrif.github.io/machine_learning/preprocessing_voice/convert_mov_gif.html</guid>
      <description>Convert video .mov to .gif first, install gifsicle:
brew install gifsicle Convert video recorded with quicktime to gif:
ffmpeg -i screen-recording.mov -s 600x400 -pix_fmt rgb24 -r 10 -f gif - | gifsicle --optimize=3 --delay=3 &amp;gt; coolest.gif </description>
    </item>
    
    <item>
      <title>Convert video</title>
      <link>https://othrif.github.io/machine_learning/preprocessing_voice/convert_video.html</link>
      <pubDate>Sun, 12 Apr 2020 14:41:32 +0200</pubDate>
      
      <guid>https://othrif.github.io/machine_learning/preprocessing_voice/convert_video.html</guid>
      <description>Convert video Convert video from one format to another:
ffmpeg -i input.mov -vcodec h264 -acodec mp2 output.mp4 Run diagnosis Run the following diagnosis for either audio or video:
ffmpeg -i output.mp4 ffprobe ouptut.mp4 </description>
    </item>
    
    <item>
      <title>Play sound in jupyter and other libraries</title>
      <link>https://othrif.github.io/machine_learning/preprocessing_voice/play_sound.html</link>
      <pubDate>Sun, 12 Apr 2020 14:41:32 +0200</pubDate>
      
      <guid>https://othrif.github.io/machine_learning/preprocessing_voice/play_sound.html</guid>
      <description>See resources here: https://realpython.com/playing-and-recording-sound-python/
filename = &amp;#39;/Users/othrif/spectrum/voice/datasets/free-spoken-digit-dataset/recordings/4_yweweler_5.wav&amp;#39; Play in CLI From sox:
play existing-file.wav Play sound in Jupyter import IPython.display as ipd ipd.Audio(filename) Your browser does not support the audio element. Play mp3 in Jupyter and load with librosa # common imports import IPython.display as ipd import librosa import warnings warnings.filterwarnings(&amp;#39;ignore&amp;#39;) newfile=&amp;#39;/Users/othrif/spectrum/voice/learning/simple_audio/test/test.mp3&amp;#39; ipd.display(ipd.Audio(newfile)) sound,sr = librosa.load(newfile) Your browser does not support the audio element. Play sound with pydub Some useful details here</description>
    </item>
    
    <item>
      <title>Record my voice</title>
      <link>https://othrif.github.io/machine_learning/preprocessing_voice/record_sound.html</link>
      <pubDate>Sun, 12 Apr 2020 14:41:32 +0200</pubDate>
      
      <guid>https://othrif.github.io/machine_learning/preprocessing_voice/record_sound.html</guid>
      <description>See resources here: https://realpython.com/playing-and-recording-sound-python/
Record in CLI From sox:
rec new-file.wav rec -b 16 -r 16000 new-file.wav Record with sounddevice import sounddevice as sd from scipy.io.wavfile import write fs = 44100 # Sample rate seconds = 3 # Duration of recording myrecording = sd.rec(int(seconds * fs), samplerate=fs, channels=1) sd.wait() # Wait until recording is finished write(&amp;#39;output.wav&amp;#39;, fs, myrecording) # Save as WAV file  import IPython.display as ipd import matplotlib.pyplot as plt ipd.</description>
    </item>
    
    <item>
      <title>Sound file properties</title>
      <link>https://othrif.github.io/machine_learning/preprocessing_voice/soundfile_prop.html</link>
      <pubDate>Sun, 12 Apr 2020 14:41:32 +0200</pubDate>
      
      <guid>https://othrif.github.io/machine_learning/preprocessing_voice/soundfile_prop.html</guid>
      <description>filename = &amp;#39;/Users/othrif/spectrum/voice/datasets/free-spoken-digit-dataset/recordings/4_yweweler_5.wav&amp;#39; In python import sox sox.file_info.info(filename) {&#39;channels&#39;: 1, &#39;sample_rate&#39;: 8000.0, &#39;bitdepth&#39;: 16, &#39;bitrate&#39;: 129000.0, &#39;duration&#39;: 0.333875, &#39;num_samples&#39;: 2671, &#39;encoding&#39;: &#39;Signed Integer PCM&#39;, &#39;silent&#39;: False}  In CLI !soxi /Users/othrif/spectrum/voice/datasets/free-spoken-digit-dataset/recordings/4_yweweler_5.wav Input File : &#39;/Users/othrif/spectrum/voice/datasets/free-spoken-digit-dataset/recordings/4_yweweler_5.wav&#39; Channels : 1 Sample Rate : 8000 Precision : 16-bit Duration : 00:00:00.33 = 2671 samples ~ 25.0406 CDDA sectors File Size : 5.39k Bit Rate : 129k Sample Encoding: 16-bit Signed Integer PCM  Convert file to a specified bit and sample rates sox &amp;lt;input&amp;gt; -b 16 -r 16000 &amp;lt;output&amp;gt; soxi &amp;lt;input&amp;gt; </description>
    </item>
    
    <item>
      <title>total time of audio</title>
      <link>https://othrif.github.io/machine_learning/preprocessing_voice/convert_mov_gif-copy1.html</link>
      <pubDate>Sun, 12 Apr 2020 14:41:32 +0200</pubDate>
      
      <guid>https://othrif.github.io/machine_learning/preprocessing_voice/convert_mov_gif-copy1.html</guid>
      <description>Calculate the total time of all audio files at a location.
EPOCH=&amp;#39;jan 1 1970&amp;#39;; sum=0; for i in `soxi * | grep Duration | awk -F&amp;#34; &amp;#34; &amp;#39;{print $3}&amp;#39; | grep :`; do sum=&amp;#34;$(date -u -d &amp;#34;$EPOCH$i&amp;#34; +%s)+ $sum&amp;#34;; done; echo &amp;#34;total = `echo $sum| bc` seconds&amp;#34; </description>
    </item>
    
    <item>
      <title>Transcribe audio: speech to text</title>
      <link>https://othrif.github.io/machine_learning/preprocessing_voice/speech_to_text.html</link>
      <pubDate>Sun, 12 Apr 2020 14:41:32 +0200</pubDate>
      
      <guid>https://othrif.github.io/machine_learning/preprocessing_voice/speech_to_text.html</guid>
      <description>filename = &amp;#39;/Users/othrif/github/dataInsights/courses/datacamp/spoken_language/stereo_phone_call.wav&amp;#39; Using speech_recognition import speech_recognition as sr recognizer = sr.Recognizer() recognizer.energy_threshold = 300 tmg_file = sr.AudioFile(filename) with tmg_file as source: tmg_audio = recognizer.record(source, duration=None, offset=None) text = recognizer.recognize_google(audio_data=tmg_audio, language=&amp;#39;en-US&amp;#39;) print(text) hello this is Daniel from Acme Studios how can I best help you I was just wondering if I could get some support yeah sure thing what&#39;s your name and what&#39;s wrong with your device and not one of large some of my my my farts okay nice to meet you Josh what&#39;s the serial number of your device so I can track it down the serial number is 176-4588  </description>
    </item>
    
  </channel>
</rss>