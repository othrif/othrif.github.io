<!DOCTYPE html>
<html lang="en">

<head>

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-162942761-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-162942761-1');
    </script>

    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<meta property="og:title" content="Basics of building a MLP" />
<meta property="og:description" content="import torch import torch.nn as nn # Performs the operation ùê¥ùë•&#43;ùëè , where ùê¥ and ùëè are initialized randomly linear = nn.Linear(10, 2) # nn.Linear(input dim=10, output dim=2) will take in a ùëõ√ó10 matrix and return an ùëõ√ó2 matrix  example_input = torch.randn(3, 10) example_output = linear(example_input) example_output tensor([[ 0.5458, 0.1715], [ 0.0310, -0.2061], [ 1.3804, -0.1380]], grad_fn=&lt;AddmmBackward&gt;)  # ReLU non-linearity sets all negative numbers in a tensor to zero relu = nn." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://othrif.github.io/machine_learning/pytorch/pynn.html" /><meta property="article:section" content="machine_learning" />
<meta property="article:published_time" content="2020-04-12T14:41:32+02:00" />
<meta property="article:modified_time" content="2020-04-12T14:41:32+02:00" />


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Basics of building a MLP"/>
<meta name="twitter:description" content="import torch import torch.nn as nn # Performs the operation ùê¥ùë•&#43;ùëè , where ùê¥ and ùëè are initialized randomly linear = nn.Linear(10, 2) # nn.Linear(input dim=10, output dim=2) will take in a ùëõ√ó10 matrix and return an ùëõ√ó2 matrix  example_input = torch.randn(3, 10) example_output = linear(example_input) example_output tensor([[ 0.5458, 0.1715], [ 0.0310, -0.2061], [ 1.3804, -0.1380]], grad_fn=&lt;AddmmBackward&gt;)  # ReLU non-linearity sets all negative numbers in a tensor to zero relu = nn."/>
<meta name="generator" content="Hugo 0.85.0" />

    
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "headline": "Basics of building a MLP",
  "url": "https:\/\/othrif.github.io\/machine_learning\/pytorch\/pynn.html",
  "wordCount": "231",
  "datePublished": "2020-04-12T14:41:32\u002b02:00",
  "dateModified": "2020-04-12T14:41:32\u002b02:00",
  "author": {
    "@type": "Person",
    "name": "Othmane Rifki"
  }
}
</script> 

    <title>Basics of building a MLP</title>

    
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb"
        crossorigin="anonymous">

    
    <link href="https://othrif.github.io/css/custom.css" rel="stylesheet">
    <link href="https://othrif.github.io/css/syntax.css" rel="stylesheet"> 
    
    <link href="https://fonts.googleapis.com/css?family=Muli:400,500,700" rel="stylesheet">

    
    <link href="" rel="alternate" type="application/rss+xml" title="Othmane Rifki All Notes And Articles" />
    
    <link href="https://othrif.github.io/articles/index.xml" rel="alternate" type="application/rss+xml" title="Othmane Rifki Articles" />

    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>

</head>

<body>

    <nav class="navbar navbar-expand-sm fixed-top">
        <div class="container">
            <a class="navbar-brand" href="https://othrif.github.io">Othmane Rifki</a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent"
                aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                    <ul class="nav navbar-nav mr-auto"></ul>
                <ul class="navbar-nav">

                    <li class="nav-item dropdown">
                        <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true"
                            aria-expanded="false">
                            Technical Notes
                        </a>
                        <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                            <a class="dropdown-item" href="https://othrif.github.io#python">Python</a>
                            <a class="dropdown-item" href="https://othrif.github.io#machine_learning">Machine Learning</a>
                            <a class="dropdown-item" href="https://othrif.github.io#linux">Linux</a>
                            <a class="dropdown-item" href="https://othrif.github.io#scripting">Scripting</a>
                            <a class="dropdown-item" href="https://othrif.github.io#coding">Coding Practice</a>
                        </div>
                    </li>
                    
                    <li class="nav-item dropdown">
                        <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true"
                            aria-expanded="false">
                            About
                        </a>
                        <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                            <a class="dropdown-item" href="https://othrif.github.io/about/othmane_rifki.html">About Othmane</a>
                            <a class="dropdown-item" href="https://github.com/othrif" target="_blank">GitHub</a>
                            <a class="dropdown-item" href="https://www.linkedin.com/in/othrif/" target="_blank">LinkedIn</a>
                            <a class="dropdown-item" href="https://twitter.com/othmanerifki" target="_blank">Twitter</a>
                        </div>
                    </li>
                </ul>
            </div>
        </div>
    </nav>


    
    <div class="container">
        <div class="row">
            <div class="col-sm-12">

                 


<article>
  <div class="technical_note">
  <header>
    <h1 class="technical_note_title">Basics of building a MLP</h1>
    <div class="technical_note_date">
      <time datetime=" 2020-04-12T14:41:32&#43;02:00 "> 12 Apr 2020</time>
    </div>
  </header>
  <div class="content">

  <div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Performs the operation  ùê¥ùë•+ùëè , where  ùê¥  and  ùëè  are initialized randomly</span>
<span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># nn.Linear(input dim=10, output dim=2) will take in a  ùëõ√ó10  matrix and return an  ùëõ√ó2  matrix </span>
<span class="n">example_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">example_output</span> <span class="o">=</span> <span class="n">linear</span><span class="p">(</span><span class="n">example_input</span><span class="p">)</span>
<span class="n">example_output</span>
</code></pre></div><pre><code>tensor([[ 0.5458,  0.1715],
        [ 0.0310, -0.2061],
        [ 1.3804, -0.1380]], grad_fn=&lt;AddmmBackward&gt;)
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># ReLU non-linearity sets all negative numbers in a tensor to zero</span>
<span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
<span class="n">relu_output</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">example_output</span><span class="p">)</span>
<span class="n">relu_output</span>
</code></pre></div><pre><code>tensor([[0.0000, 0.3189],
        [0.0000, 0.6577],
        [0.1315, 0.0000]], grad_fn=&lt;ReluBackward0&gt;)
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Rescale a batch of  ùëõ  inputs to have a consistent mean and standard deviation between batches</span>
<span class="n">batchnorm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">batchnorm_output</span> <span class="o">=</span> <span class="n">batchnorm</span><span class="p">(</span><span class="n">relu_output</span><span class="p">)</span>
<span class="n">batchnorm_output</span>
</code></pre></div><pre><code>tensor([[-0.7062, -0.0247],
        [-0.7062,  1.2368],
        [ 1.4124, -1.2121]], grad_fn=&lt;NativeBatchNormBackward&gt;)
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># do it with one operation</span>
<span class="n">mlp_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="p">)</span>

<span class="n">test_example</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&#34;input: &#34;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_example</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&#34;output: &#34;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mlp_layer</span><span class="p">(</span><span class="n">test_example</span><span class="p">))</span>
</code></pre></div><pre><code>input: 
tensor([[ 1.4355,  0.1143,  0.0974,  0.2137,  1.9092],
        [-0.7489, -1.7915,  0.3816, -0.0109,  1.3555],
        [-1.8546, -2.9966,  0.5250, -0.4175,  1.0728],
        [ 0.5806, -0.6192, -0.0937, -1.3968,  0.8309],
        [-1.2107, -0.3949,  0.8021, -0.7953, -0.5259]])
output: 
tensor([[-0.8080,  1.9998],
        [-0.8080, -0.5000],
        [-0.8080, -0.5000],
        [ 0.9855, -0.5000],
        [ 1.4384, -0.5000]], grad_fn=&lt;NativeBatchNormBackward&gt;)
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Optimizer</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="n">adam_opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">mlp_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">train_example</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">adam_opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>  
    <span class="c1"># Loss function</span>
    <span class="n">cur_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">mlp_layer</span><span class="p">(</span><span class="n">train_example</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">cur_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">adam_opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">cur_loss</span><span class="p">)</span>
</code></pre></div><pre><code>tensor(0.5653, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.4999, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.4354, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.3699, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.3009, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.2271, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.1474, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.0749, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.0687, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.1651, grad_fn=&lt;MeanBackward0&gt;)
</code></pre>

</div>
  <aside>
      <div class="bug_reporting">
          <h4>Find an error?</h4>
          <p>All material is saved on GitHub. Please <a href='https://github.com/othrif/notes_othmanerifki/issues/new'>submit a suggested change</a> and include the note's URL in the issue.</p>
      </div>
      </aside>

    </div>
</article>




            </div>

        </div>
    </div>

    

    <footer class="footer text-center">
        <div class="container">
            <span class="text-muted">Copyright &copy; Othmane Rifki, <time datetime="2020">2020</time>. All 145 notes and articles are available on <a href="https://github.com/othrif/">GitHub</a>.</span>
        </div>
    </footer>

    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" integrity="sha384-vFJXuSJphROIrBnz7yo7oB41mKfc8JzQZiCq4NCceLEaO4IHwicKwpJf9c9IpFgh"
        crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" integrity="sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ"
        crossorigin="anonymous"></script>

</body>

</html>