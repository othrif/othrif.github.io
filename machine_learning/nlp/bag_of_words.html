<!DOCTYPE html>
<html lang="en">

<head>

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-162942761-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-162942761-1');
    </script>

    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<meta property="og:title" content="Bag of words" />
<meta property="og:description" content="Transforming documents into feature vectors By calling the fit_transform method on CountVectorizer, we just constructed the vocabulary of the bag-of-words model and transformed the following three sentences into sparse feature vectors
import numpy as np from sklearn.feature_extraction.text import CountVectorizer count = CountVectorizer() docs = np.array([ &#39;The sun is shining&#39;, &#39;The weather is sweet&#39;, &#39;The sun is shining, the weather is sweet, and one and one is two&#39;]) bag = count.fit_transform(docs) Content of the vocabulary:" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://othrif.github.io/machine_learning/nlp/bag_of_words.html" /><meta property="article:section" content="machine_learning" />
<meta property="article:published_time" content="2020-04-12T14:41:32+02:00" />
<meta property="article:modified_time" content="2020-04-12T14:41:32+02:00" />


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Bag of words"/>
<meta name="twitter:description" content="Transforming documents into feature vectors By calling the fit_transform method on CountVectorizer, we just constructed the vocabulary of the bag-of-words model and transformed the following three sentences into sparse feature vectors
import numpy as np from sklearn.feature_extraction.text import CountVectorizer count = CountVectorizer() docs = np.array([ &#39;The sun is shining&#39;, &#39;The weather is sweet&#39;, &#39;The sun is shining, the weather is sweet, and one and one is two&#39;]) bag = count.fit_transform(docs) Content of the vocabulary:"/>
<meta name="generator" content="Hugo 0.85.0" />

    
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "headline": "Bag of words",
  "url": "https:\/\/othrif.github.io\/machine_learning\/nlp\/bag_of_words.html",
  "wordCount": "597",
  "datePublished": "2020-04-12T14:41:32\u002b02:00",
  "dateModified": "2020-04-12T14:41:32\u002b02:00",
  "author": {
    "@type": "Person",
    "name": "Othmane Rifki"
  }
}
</script> 

    <title>Bag of words</title>

    
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb"
        crossorigin="anonymous">

    
    <link href="https://othrif.github.io/css/custom.css" rel="stylesheet">
    <link href="https://othrif.github.io/css/syntax.css" rel="stylesheet"> 
    
    <link href="https://fonts.googleapis.com/css?family=Muli:400,500,700" rel="stylesheet">

    
    <link href="" rel="alternate" type="application/rss+xml" title="Othmane Rifki All Notes And Articles" />
    
    <link href="https://othrif.github.io/articles/index.xml" rel="alternate" type="application/rss+xml" title="Othmane Rifki Articles" />

    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>

</head>

<body>

    <nav class="navbar navbar-expand-sm fixed-top">
        <div class="container">
            <a class="navbar-brand" href="https://othrif.github.io">Othmane Rifki</a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent"
                aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                    <ul class="nav navbar-nav mr-auto"></ul>
                <ul class="navbar-nav">

                    <li class="nav-item dropdown">
                        <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true"
                            aria-expanded="false">
                            Technical Notes
                        </a>
                        <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                            <a class="dropdown-item" href="https://othrif.github.io#python">Python</a>
                            <a class="dropdown-item" href="https://othrif.github.io#machine_learning">Machine Learning</a>
                            <a class="dropdown-item" href="https://othrif.github.io#linux">Linux</a>
                            <a class="dropdown-item" href="https://othrif.github.io#scripting">Scripting</a>
                            <a class="dropdown-item" href="https://othrif.github.io#coding">Coding Practice</a>
                        </div>
                    </li>
                    
                    <li class="nav-item dropdown">
                        <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true"
                            aria-expanded="false">
                            About
                        </a>
                        <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                            <a class="dropdown-item" href="https://othrif.github.io/about/othmane_rifki.html">About Othmane</a>
                            <a class="dropdown-item" href="https://github.com/othrif" target="_blank">GitHub</a>
                            <a class="dropdown-item" href="https://www.linkedin.com/in/othrif/" target="_blank">LinkedIn</a>
                            <a class="dropdown-item" href="https://twitter.com/othmanerifki" target="_blank">Twitter</a>
                        </div>
                    </li>
                </ul>
            </div>
        </div>
    </nav>


    
    <div class="container">
        <div class="row">
            <div class="col-sm-12">

                 


<article>
  <div class="technical_note">
  <header>
    <h1 class="technical_note_title">Bag of words</h1>
    <div class="technical_note_date">
      <time datetime=" 2020-04-12T14:41:32&#43;02:00 "> 12 Apr 2020</time>
    </div>
  </header>
  <div class="content">

  <h3 id="transforming-documents-into-feature-vectors">Transforming documents into feature vectors</h3>
<p>By calling the fit_transform method on CountVectorizer, we just constructed the vocabulary of the bag-of-words model and transformed the following three sentences into sparse feature vectors</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">count</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="s1">&#39;The sun is shining&#39;</span><span class="p">,</span>
        <span class="s1">&#39;The weather is sweet&#39;</span><span class="p">,</span>
        <span class="s1">&#39;The sun is shining, the weather is sweet, and one and one is two&#39;</span><span class="p">])</span>
<span class="n">bag</span> <span class="o">=</span> <span class="n">count</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</code></pre></div><p>Content of the vocabulary:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">count</span><span class="o">.</span><span class="n">vocabulary_</span><span class="p">)</span>
</code></pre></div><pre><code>{'the': 6, 'sun': 4, 'is': 1, 'shining': 3, 'weather': 8, 'sweet': 5, 'and': 0, 'one': 2, 'two': 7}
</code></pre>
<p>Each index position in the feature vectors shown here corresponds to the integer values that are stored as dictionary items in the CountVectorizer vocabulary.
Those values in the feature vectors are also called the raw term frequencies: tf (t,d)â€”the number of times a term t occurs in a document d.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="n">bag</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
</code></pre></div><pre><code>[[0 1 0 1 1 0 1 0 0]
 [0 1 0 0 0 1 1 0 1]
 [2 3 2 1 1 1 2 1 1]]
</code></pre>
<h3 id="assessing-word-relevancy-via-term-frequency-inverse-document-frequency">Assessing word relevancy via term frequency-inverse document frequency</h3>
<p>When we are analyzing text data, we often encounter words that occur across multiple documents from both classes. Those frequently occurring words typically don&rsquo;t contain useful or discriminatory information. Frequency-inverse document frequency (tf-idf) that can be used to downweight those frequently occurring words in the feature vectors.</p>
<p>The tf-idf can be defined as the product of the term frequency and the inverse document frequency:<br>
$\text{tf-idf}(t,d)=\text{tf (t,d)}\times \text{idf}(t,d)$</p>
<p>The inverse document frequency <strong>idf(t, d)</strong> can be calculated as: <br>
$\text{idf}(t,d) = \text{log}\frac{n_d}{1+\text{df}(d, t)}$ <br>
where $n_d$ is the total number of documents, and <strong>df(d, t)</strong> is the number of documents <em>d</em> that contain the term <em>t</em>.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfTransformer</span>

<span class="n">tfidf</span> <span class="o">=</span> <span class="n">TfidfTransformer</span><span class="p">(</span><span class="n">use_idf</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                         <span class="n">norm</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span> 
                         <span class="n">smooth_idf</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tfidf</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">count</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">))</span>
      <span class="o">.</span><span class="n">toarray</span><span class="p">())</span>

</code></pre></div><pre><code>[[0.   0.43 0.   0.56 0.56 0.   0.43 0.   0.  ]
 [0.   0.43 0.   0.   0.   0.56 0.43 0.   0.56]
 [0.5  0.45 0.5  0.19 0.19 0.19 0.3  0.25 0.19]]
</code></pre>
<p>Equivalent to</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">tfidf</span> <span class="o">=</span> <span class="n">TfidfTransformer</span><span class="p">(</span><span class="n">use_idf</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">smooth_idf</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">raw_tfidf</span> <span class="o">=</span> <span class="n">tfidf</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">count</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">))</span><span class="o">.</span><span class="n">toarray</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Last document</span>
<span class="n">raw_tfidf</span>
</code></pre></div><pre><code>array([3.39, 3.  , 3.39, 1.29, 1.29, 1.29, 2.  , 1.69, 1.29])
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">l2_tfidf</span> <span class="o">=</span> <span class="n">raw_tfidf</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">raw_tfidf</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
<span class="n">l2_tfidf</span>
</code></pre></div><pre><code>array([0.5 , 0.45, 0.5 , 0.19, 0.19, 0.19, 0.3 , 0.25, 0.19])
</code></pre>
<h3 id="combine-both-bagging-and-tfidf">Combine both bagging and tfidf</h3>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<span class="n">tfidf</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">strip_accents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">lowercase</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">preprocessor</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">tfidf</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</code></pre></div><pre><code>array([[0.43, 0.  , 0.43, 0.  , 0.56, 0.56, 0.  , 0.  , 0.  , 0.  ],
       [0.43, 0.  , 0.43, 0.  , 0.  , 0.  , 0.56, 0.  , 0.  , 0.56],
       [0.15, 0.5 , 0.45, 0.5 , 0.19, 0.19, 0.19, 0.25, 0.25, 0.19]])
</code></pre>
<h3 id="calculation-by-hand">Calculation by hand</h3>
<p>Calculation of the tf-idf computed by scikitlear is:<br>
$\text{idf}(t,d) = \text{log}\frac{1 + n_d}{1+\text{df}(d, t)}$  <br>
$\text{tf-idf}(t,d)=\text{tf (t,d)}\times \left( 1 + \text{idf}(t,d) \right)$</p>
<p><strong>tf(t,d)</strong>: How many times the term t appears in document d.<br>
<strong>df(d,t)</strong>: How many documents have the term t.</p>
<p>In the example of the 3rd document, the term &lsquo;and&rsquo; appears 2 times:<br>
$\text{tf}(&lsquo;and&rsquo;, d3) = 2$<br>
$\text{df}(d, &lsquo;and&rsquo;)  = 1$<br>
$\text{idf}(&lsquo;and&rsquo;, d3) = \text{log}\frac{1 + 3}{1 + 1} = 0.69$<br>
$\text{tf-idf}(&lsquo;and&rsquo;, d3) = 2 * (1 + log(2)) = 3.39$</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">tf_and</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">df_and</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">n_docs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">idf_and</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span> <span class="o">+</span> <span class="n">n_docs</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">df_and</span><span class="p">))</span>
<span class="n">tfidf_and</span> <span class="o">=</span> <span class="n">tf_and</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">idf_and</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;tf-idf of term &#34;and&#34; = </span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">tfidf_and</span><span class="p">)</span>
</code></pre></div><pre><code>tf-idf of term &quot;and&quot; = 3.39
</code></pre>
<p>Repeating the caclucation bove, we obtain:</p>
<p>$\text{tf-idf}(d3) = [3.39, 3.  , 3.39, 1.29, 1.29, 1.29, 2.  , 1.69, 1.29]$</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">raw_tfidf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">3.39</span><span class="p">,</span> <span class="mf">3.</span>  <span class="p">,</span> <span class="mf">3.39</span><span class="p">,</span> <span class="mf">1.29</span><span class="p">,</span> <span class="mf">1.29</span><span class="p">,</span> <span class="mf">1.29</span><span class="p">,</span> <span class="mf">2.</span>  <span class="p">,</span> <span class="mf">1.69</span><span class="p">,</span> <span class="mf">1.29</span><span class="p">])</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;tf-idf normalized is: </span><span class="si">{</span><span class="n">raw_tfidf</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">raw_tfidf</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div><pre><code>tf-idf normalized is: [0.5  0.44 0.5  0.19 0.19 0.19 0.3  0.25 0.19]
</code></pre>

</div>
  <aside>
      <div class="bug_reporting">
          <h4>Find an error?</h4>
          <p>All material is saved on GitHub. Please <a href='https://github.com/othrif/notes_othmanerifki/issues/new'>submit a suggested change</a> and include the note's URL in the issue.</p>
      </div>
      </aside>

    </div>
</article>




            </div>

        </div>
    </div>

    

    <footer class="footer text-center">
        <div class="container">
            <span class="text-muted">Copyright &copy; Othmane Rifki, <time datetime="2020">2020</time>. All 147 notes and articles are available on <a href="https://github.com/othrif/">GitHub</a>.</span>
        </div>
    </footer>

    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" integrity="sha384-vFJXuSJphROIrBnz7yo7oB41mKfc8JzQZiCq4NCceLEaO4IHwicKwpJf9c9IpFgh"
        crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" integrity="sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ"
        crossorigin="anonymous"></script>

</body>

</html>