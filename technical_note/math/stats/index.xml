<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Othmane Rifki</title>
    <link>http://othrif.github.io/technical_note/math/stats/</link>
      <atom:link href="http://othrif.github.io/technical_note/math/stats/index.xml" rel="self" type="application/rss+xml" />
    <description>Othmane Rifki</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sun, 12 Apr 2020 14:41:32 +0200</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Othmane Rifki</title>
      <link>http://othrif.github.io/technical_note/math/stats/</link>
    </image>
    
    <item>
      <title>Centrality, variability, modality</title>
      <link>http://othrif.github.io/technical_note/math/stats/descriptive/</link>
      <pubDate>Sun, 12 Apr 2020 14:41:32 +0200</pubDate>
      <guid>http://othrif.github.io/technical_note/math/stats/descriptive/</guid>
      <description>&lt;h3 id=&#34;centrality&#34;&gt;Centrality&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Mean&lt;/li&gt;
&lt;li&gt;Median&lt;/li&gt;
&lt;li&gt;Mode&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;variability&#34;&gt;Variability&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Variance ($\sigma^2$): Measurement of the spread between numbers in a data set&lt;/li&gt;
&lt;li&gt;Standard deviation ($\sigma$): square root of the variance&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;True population variance: $ \sigma^2 = \frac{\sum{\left(x-\mu\right)^2}}{N} $ &lt;br&gt;
Unbiased sample variance: $ \sigma^2 = \frac{\sum{\left(x-\bar{x}\right)^2}}{n-1} $ &lt;br&gt;
Biased sample variance: $ \sigma^2 = \frac{\sum{\left(x-\bar{x}\right)^2}}{n} $&lt;/p&gt;
&lt;p&gt;We typically want the unbiased sample variance&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def calc_mean(x, n):
    return sum(x)/n

def calc_var(x, n):
    &#39;&#39;&#39;
    Calculate variance using numpy array x
    &#39;&#39;&#39;
    mean = calc_mean(x,n)
    return sum(np.power(x-mean,2))/n

def calc_var_list(x, n):
    &#39;&#39;&#39;
    Calculate variance using list x
    &#39;&#39;&#39;
    mean = sum(x)/n
    return sum( pow(el - mean,2) for el in x )/n
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;nums = [1, 2, 3, 4, 5]
nums_arr = np.array(nums)
print(f&#39;Variance calculated using a numpy array: {calc_var(nums_arr, len(nums_arr))}&#39;)
print(f&#39;Variance calculated using a list : {calc_var_list(nums, len(nums))}&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Variance calculated using a numpy array: 2.0
Variance calculated using a list : 2.0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
from matplotlib import pyplot as plt

N = 100000 # population size
population =  np.random.randint(1, 101, N)
true_mean = calc_mean(population, N)
true_var  = calc_var(population, N)
plt.title(&#39;Uniform distribution&#39;)
plt.hist(population)
plt.show()
print(f&#39;Popluation true mean: {population.mean():.2f}, calculated: {true_mean:.2f}&#39;)
print(f&#39;Popluation true variance: {population.var():.2f}, calculated: {true_var:.2f}&#39;)

cum_mean_var = {&#39;mean&#39;: [], &#39;var&#39;: [], &#39;var_unb&#39;: []}

for i in range(100):
    pop = np.random.choice(population, int((i+1)/100 * N))
    cum_mean_var[&#39;mean&#39;].append(calc_mean(pop, len(pop)))
    cum_mean_var[&#39;var&#39;].append(calc_var(pop, len(pop)))
    cum_mean_var[&#39;var_unb&#39;].append(calc_var(pop, len(pop)-1))
plt.plot(cum_mean_var[&#39;mean&#39;])
plt.title(&#39;Cumulative sample mean&#39;)
plt.hlines(true_mean, 0,100, colors=&#39;r&#39;)
plt.show()
plt.title(&#39;Cumulative sample biased variance&#39;)
plt.plot(cum_mean_var[&#39;var&#39;])
plt.hlines(true_var, 0,100, colors=&#39;r&#39;)
plt.show()
plt.title(&#39;Cumulative sample unbiased variance&#39;)
plt.plot(cum_mean_var[&#39;var_unb&#39;])
plt.hlines(true_var, 0,100, colors=&#39;r&#39;)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;descriptive_5_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Popluation true mean: 50.47, calculated: 50.47
Popluation true variance: 833.32, calculated: 833.32
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;descriptive_5_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;descriptive_5_3.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;descriptive_5_4.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;I don&amp;rsquo;t see a clear distinction between biased (/n) and unbiased (/(n-1))sample variance.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Confidence Interval</title>
      <link>http://othrif.github.io/technical_note/math/stats/cl/</link>
      <pubDate>Sun, 12 Apr 2020 14:41:32 +0200</pubDate>
      <guid>http://othrif.github.io/technical_note/math/stats/cl/</guid>
      <description>&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from scipy.stats import sem, t
data = [1, 2, 3, 4, 5]
confidence = 0.95
z_score = 2.7764451051977987
sample_mean = 3.0

# Compute the standard error and margin of error
std_err = sem(data)
margin_error = std_err * z_score

# Compute and print the lower threshold
lower = sample_mean - margin_error
print(lower)

# Compute and print the upper threshold
upper = sample_mean + margin_error
print(upper)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;1.036756838522439
4.9632431614775605
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from statsmodels.stats.proportion import proportion_confint
# Compute and print the 99% confidence interval
heads = 27
confidence_int = proportion_confint(heads, 50, 0.01)
print(confidence_int)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;(0.35844514241179504, 0.721554857588205)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Compute and print the 90% confidence interval
confidence_int = proportion_confint(heads, 50, 0.1)
print(confidence_int)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;(0.42406406993539053, 0.6559359300646095)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from scipy.stats import binom
# Repeat this process 10 times 
heads = binom.rvs(50, 0.5, size=10)
for val in heads:
    confidence_interval = proportion_confint(val, 50, .10)
    print(confidence_interval)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;(0.3836912846323326, 0.6163087153676674)
(0.42406406993539053, 0.6559359300646095)
(0.2860411978842442, 0.5139588021157558)
(0.36378436885322046, 0.5962156311467796)
(0.3440640699353905, 0.5759359300646095)
(0.42406406993539053, 0.6559359300646095)
(0.2860411978842442, 0.5139588021157558)
(0.2860411978842442, 0.5139588021157558)
(0.5498070827050113, 0.7701929172949887)
(0.46518968814451866, 0.6948103118554813)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Examine your confidence interval results from the last step. You might see at least one confidence interval that does not contain 0.5, the true population proportion for a fair coin flip. You could decrease the likelihood of this happening by increasing your confidence level or lowering the alpha value.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Encoding techniques</title>
      <link>http://othrif.github.io/technical_note/math/stats/encoding/</link>
      <pubDate>Sun, 12 Apr 2020 14:41:32 +0200</pubDate>
      <guid>http://othrif.github.io/technical_note/math/stats/encoding/</guid>
      <description>&lt;h3 id=&#34;centrality&#34;&gt;Centrality&lt;/h3&gt;
&lt;p&gt;label encoding and one-hot encoding.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;laptops = pd.read_csv(&#39;laptops.csv&#39; , encoding=&#39;latin-1&#39;, index_col=0) # added encoding because of errors
laptops = laptops.loc[laptops[&#39;Company&#39;].isin([&#39;Apple&#39;, &#39;Dell&#39;, &#39;Lenovo&#39;])] 
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;laptops.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Company&lt;/th&gt;
      &lt;th&gt;Product&lt;/th&gt;
      &lt;th&gt;TypeName&lt;/th&gt;
      &lt;th&gt;Inches&lt;/th&gt;
      &lt;th&gt;ScreenResolution&lt;/th&gt;
      &lt;th&gt;Cpu&lt;/th&gt;
      &lt;th&gt;Ram&lt;/th&gt;
      &lt;th&gt;Memory&lt;/th&gt;
      &lt;th&gt;Gpu&lt;/th&gt;
      &lt;th&gt;OpSys&lt;/th&gt;
      &lt;th&gt;Weight&lt;/th&gt;
      &lt;th&gt;Price_euros&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Apple&lt;/td&gt;
      &lt;td&gt;MacBook Pro&lt;/td&gt;
      &lt;td&gt;Ultrabook&lt;/td&gt;
      &lt;td&gt;13.3&lt;/td&gt;
      &lt;td&gt;IPS Panel Retina Display 2560x1600&lt;/td&gt;
      &lt;td&gt;Intel Core i5 2.3GHz&lt;/td&gt;
      &lt;td&gt;8GB&lt;/td&gt;
      &lt;td&gt;128GB SSD&lt;/td&gt;
      &lt;td&gt;Intel Iris Plus Graphics 640&lt;/td&gt;
      &lt;td&gt;macOS&lt;/td&gt;
      &lt;td&gt;1.37kg&lt;/td&gt;
      &lt;td&gt;1339.69&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Apple&lt;/td&gt;
      &lt;td&gt;Macbook Air&lt;/td&gt;
      &lt;td&gt;Ultrabook&lt;/td&gt;
      &lt;td&gt;13.3&lt;/td&gt;
      &lt;td&gt;1440x900&lt;/td&gt;
      &lt;td&gt;Intel Core i5 1.8GHz&lt;/td&gt;
      &lt;td&gt;8GB&lt;/td&gt;
      &lt;td&gt;128GB Flash Storage&lt;/td&gt;
      &lt;td&gt;Intel HD Graphics 6000&lt;/td&gt;
      &lt;td&gt;macOS&lt;/td&gt;
      &lt;td&gt;1.34kg&lt;/td&gt;
      &lt;td&gt;898.94&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;Apple&lt;/td&gt;
      &lt;td&gt;MacBook Pro&lt;/td&gt;
      &lt;td&gt;Ultrabook&lt;/td&gt;
      &lt;td&gt;15.4&lt;/td&gt;
      &lt;td&gt;IPS Panel Retina Display 2880x1800&lt;/td&gt;
      &lt;td&gt;Intel Core i7 2.7GHz&lt;/td&gt;
      &lt;td&gt;16GB&lt;/td&gt;
      &lt;td&gt;512GB SSD&lt;/td&gt;
      &lt;td&gt;AMD Radeon Pro 455&lt;/td&gt;
      &lt;td&gt;macOS&lt;/td&gt;
      &lt;td&gt;1.83kg&lt;/td&gt;
      &lt;td&gt;2537.45&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;Apple&lt;/td&gt;
      &lt;td&gt;MacBook Pro&lt;/td&gt;
      &lt;td&gt;Ultrabook&lt;/td&gt;
      &lt;td&gt;13.3&lt;/td&gt;
      &lt;td&gt;IPS Panel Retina Display 2560x1600&lt;/td&gt;
      &lt;td&gt;Intel Core i5 3.1GHz&lt;/td&gt;
      &lt;td&gt;8GB&lt;/td&gt;
      &lt;td&gt;256GB SSD&lt;/td&gt;
      &lt;td&gt;Intel Iris Plus Graphics 650&lt;/td&gt;
      &lt;td&gt;macOS&lt;/td&gt;
      &lt;td&gt;1.37kg&lt;/td&gt;
      &lt;td&gt;1803.60&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;td&gt;Apple&lt;/td&gt;
      &lt;td&gt;MacBook Pro&lt;/td&gt;
      &lt;td&gt;Ultrabook&lt;/td&gt;
      &lt;td&gt;15.4&lt;/td&gt;
      &lt;td&gt;IPS Panel Retina Display 2880x1800&lt;/td&gt;
      &lt;td&gt;Intel Core i7 2.2GHz&lt;/td&gt;
      &lt;td&gt;16GB&lt;/td&gt;
      &lt;td&gt;256GB Flash Storage&lt;/td&gt;
      &lt;td&gt;Intel Iris Pro Graphics&lt;/td&gt;
      &lt;td&gt;Mac OS X&lt;/td&gt;
      &lt;td&gt;2.04kg&lt;/td&gt;
      &lt;td&gt;2139.97&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;h3 id=&#34;label-encoding&#34;&gt;Label encoding&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sklearn import preprocessing
# Create the encoder and print our encoded new_vals
encoder = preprocessing.LabelEncoder()
new_vals = encoder.fit_transform(laptops[&#39;Company&#39;])
print(new_vals)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[0 0 0 0 0 0 0 1 0 0 1 0 2 1 2 1 1 0 1 1 1 0 2 1 1 1 0 2 1 2 1 1 1 2 2 1 1
 2 1 1 0 2 1 1 1 1 1 1 2 2 1 2 1 1 2 1 1 1 2 2 2 2 1 1 2 2 1 1 2 1 2 1 2 1
 1 2 1 1 2 1 2 2 1 1 2 2 1 2 1 1 1 2 2 1 2 1 1 1 2 1 1 2 1 1 2 1 2 1 0 1 2
 1 2 1 2 1 1 1 2 2 0 1 2 1 1 2 2 2 1 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2 1 1 2 2
 2 1 2 1 1 1 2 2 1 2 1 1 1 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 2 2 2 1 1 2 1 2 2
 1 2 2 2 1 2 2 2 2 1 1 1 2 2 1 1 1 1 2 2 2 2 2 2 1 2 2 1 1 1 2 1 1 1 2 2 1
 2 1 1 1 2 1 1 1 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 1 2 2 2 1 1 1 1 1
 2 1 1 2 2 2 2 1 1 2 1 2 2 1 1 2 2 2 2 2 1 1 1 1 2 2 2 1 2 2 2 2 1 1 1 2 2
 2 1 1 1 1 1 2 1 2 2 1 1 2 2 1 2 2 1 2 2 2 2 1 1 1 2 1 1 2 2 1 2 2 2 1 2 1
 1 2 2 2 2 1 2 2 2 2 1 2 2 2 1 1 1 2 1 2 2 2 1 2 1 1 1 1 2 2 1 1 1 2 2 1 2
 2 2 1 2 1 1 1 1 1 2 1 2 2 2 1 2 2 0 2 1 2 1 1 1 1 1 2 1 1 2 1 1 2 2 2 1 2
 2 2 1 2 1 1 1 1 2 1 1 2 2 2 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 1 1 1 2 2 2 1 2
 2 1 1 2 1 2 1 2 2 1 1 1 2 2 1 2 1 1 2 1 1 1 2 1 1 1 2 1 1 1 2 1 2 1 2 1 1
 2 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 0 1 2 2 2 2 2 2 2 1 2 1 1 1 1
 1 2 1 2 1 2 2 1 2 1 2 2 2 2 2 1 2 1 2 2 2 1 1 2 2 2 2 1 2 2 2 2 2 2 2 2 1
 1 1 2 0 1 2 1 2 1 1 1 2 0 1 2 2 2 1 1 1 1 2 2 1 0 1 2 2 1 1 2 1 1 2 2 1 1
 2 2 1 1 2 1 2 2 2 1 1 2 1 2 2 2 1 1 2 1 2 2 2]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;one-hot-encode&#34;&gt;One-hot encode&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# One-hot encode Company for laptops2
laptops2 = pd.get_dummies(data=laptops, columns=[&#39;Company&#39;])
laptops2.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
&lt;pre&gt;&lt;code&gt;.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/style&gt;&lt;/p&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Product&lt;/th&gt;
      &lt;th&gt;TypeName&lt;/th&gt;
      &lt;th&gt;Inches&lt;/th&gt;
      &lt;th&gt;ScreenResolution&lt;/th&gt;
      &lt;th&gt;Cpu&lt;/th&gt;
      &lt;th&gt;Ram&lt;/th&gt;
      &lt;th&gt;Memory&lt;/th&gt;
      &lt;th&gt;Gpu&lt;/th&gt;
      &lt;th&gt;OpSys&lt;/th&gt;
      &lt;th&gt;Weight&lt;/th&gt;
      &lt;th&gt;Price_euros&lt;/th&gt;
      &lt;th&gt;Company_Apple&lt;/th&gt;
      &lt;th&gt;Company_Dell&lt;/th&gt;
      &lt;th&gt;Company_Lenovo&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;MacBook Pro&lt;/td&gt;
      &lt;td&gt;Ultrabook&lt;/td&gt;
      &lt;td&gt;13.3&lt;/td&gt;
      &lt;td&gt;IPS Panel Retina Display 2560x1600&lt;/td&gt;
      &lt;td&gt;Intel Core i5 2.3GHz&lt;/td&gt;
      &lt;td&gt;8GB&lt;/td&gt;
      &lt;td&gt;128GB SSD&lt;/td&gt;
      &lt;td&gt;Intel Iris Plus Graphics 640&lt;/td&gt;
      &lt;td&gt;macOS&lt;/td&gt;
      &lt;td&gt;1.37kg&lt;/td&gt;
      &lt;td&gt;1339.69&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Macbook Air&lt;/td&gt;
      &lt;td&gt;Ultrabook&lt;/td&gt;
      &lt;td&gt;13.3&lt;/td&gt;
      &lt;td&gt;1440x900&lt;/td&gt;
      &lt;td&gt;Intel Core i5 1.8GHz&lt;/td&gt;
      &lt;td&gt;8GB&lt;/td&gt;
      &lt;td&gt;128GB Flash Storage&lt;/td&gt;
      &lt;td&gt;Intel HD Graphics 6000&lt;/td&gt;
      &lt;td&gt;macOS&lt;/td&gt;
      &lt;td&gt;1.34kg&lt;/td&gt;
      &lt;td&gt;898.94&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;MacBook Pro&lt;/td&gt;
      &lt;td&gt;Ultrabook&lt;/td&gt;
      &lt;td&gt;15.4&lt;/td&gt;
      &lt;td&gt;IPS Panel Retina Display 2880x1800&lt;/td&gt;
      &lt;td&gt;Intel Core i7 2.7GHz&lt;/td&gt;
      &lt;td&gt;16GB&lt;/td&gt;
      &lt;td&gt;512GB SSD&lt;/td&gt;
      &lt;td&gt;AMD Radeon Pro 455&lt;/td&gt;
      &lt;td&gt;macOS&lt;/td&gt;
      &lt;td&gt;1.83kg&lt;/td&gt;
      &lt;td&gt;2537.45&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;MacBook Pro&lt;/td&gt;
      &lt;td&gt;Ultrabook&lt;/td&gt;
      &lt;td&gt;13.3&lt;/td&gt;
      &lt;td&gt;IPS Panel Retina Display 2560x1600&lt;/td&gt;
      &lt;td&gt;Intel Core i5 3.1GHz&lt;/td&gt;
      &lt;td&gt;8GB&lt;/td&gt;
      &lt;td&gt;256GB SSD&lt;/td&gt;
      &lt;td&gt;Intel Iris Plus Graphics 650&lt;/td&gt;
      &lt;td&gt;macOS&lt;/td&gt;
      &lt;td&gt;1.37kg&lt;/td&gt;
      &lt;td&gt;1803.60&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;td&gt;MacBook Pro&lt;/td&gt;
      &lt;td&gt;Ultrabook&lt;/td&gt;
      &lt;td&gt;15.4&lt;/td&gt;
      &lt;td&gt;IPS Panel Retina Display 2880x1800&lt;/td&gt;
      &lt;td&gt;Intel Core i7 2.2GHz&lt;/td&gt;
      &lt;td&gt;16GB&lt;/td&gt;
      &lt;td&gt;256GB Flash Storage&lt;/td&gt;
      &lt;td&gt;Intel Iris Pro Graphics&lt;/td&gt;
      &lt;td&gt;Mac OS X&lt;/td&gt;
      &lt;td&gt;2.04kg&lt;/td&gt;
      &lt;td&gt;2139.97&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>How to determine a sample size</title>
      <link>http://othrif.github.io/technical_note/math/stats/power_sample/</link>
      <pubDate>Sun, 12 Apr 2020 14:41:32 +0200</pubDate>
      <guid>http://othrif.github.io/technical_note/math/stats/power_sample/</guid>
      <description>&lt;p&gt;Let&amp;rsquo;s finish up our dive into statistical tests by performing power analysis to generate needed sample size. Power analysis involves four moving parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sample size&lt;/li&gt;
&lt;li&gt;Effect size&lt;/li&gt;
&lt;li&gt;Minimum effect&lt;/li&gt;
&lt;li&gt;significance level = P(Type I error) = probability of finding an effect that is not there&lt;/li&gt;
&lt;li&gt;power = 1 - P(Type II error) = probability of finding an effect that is there&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;exercise&#34;&gt;Exercise&lt;/h3&gt;
&lt;p&gt;In this exercise, you&amp;rsquo;re working with a website and want to test for a difference in conversion rate. Before you begin the experiment, you must decide how many samples you&amp;rsquo;ll need per variant using 5% significance and 95% power.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Standardize the effect size
from statsmodels.stats.proportion import proportion_effectsize
std_effect = proportion_effectsize(.20, .25)

# Assign and print the needed sample size
from statsmodels.stats.power import  zt_ind_solve_power
sample_size = zt_ind_solve_power(effect_size=std_effect, nobs1=None, alpha=0.05, power=0.95)
print(sample_size)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;1807.7621477153323
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Assign and print the needed sample size
from statsmodels.stats.power import  zt_ind_solve_power
sample_size = zt_ind_solve_power(effect_size=std_effect, nobs1=None, alpha=.05, power=0.8)
print(sample_size)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;1091.8961587171991
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice how lowering the power allowed you fewer observations in your sample, yet increased your chance of a Type II error.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sample_sizes = np.array(range(5, 100))
effect_sizes = np.array([0.2, 0.5, 0.8])

# Create results object for t-test analysis
from statsmodels.stats.power import TTestIndPower
results = TTestIndPower()

#Plot the power analysis
import matplotlib.pyplot as plt
results.plot_power(dep_var=&#39;nobs&#39;, nobs=sample_sizes, effect_size=effect_sizes)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;power_sample_6_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Notice that not only does an increase in power result in a larger sample size, but this increase grows exponentially as the minimum effect size is increased.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Look-elsewhere effect</title>
      <link>http://othrif.github.io/technical_note/math/stats/look_elsewhere/</link>
      <pubDate>Sun, 12 Apr 2020 14:41:32 +0200</pubDate>
      <guid>http://othrif.github.io/technical_note/math/stats/look_elsewhere/</guid>
      <description>&lt;p&gt;The probability of encountering an error is still extremely high. This is where the Bonferroni correction comes in. While a bit conservative, it controls the family-wise error rate for circumstances like these to avoid the high probability of a Type I error.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Print error rate for 60 tests with 5% significance
error_rate = 1 - (.95**(60))
print(error_rate)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;0.953930201013048
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Print error rate for 30 tests with 5% significance
error_rate = 1 - (.95**(30))
print(error_rate)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;0.7853612360570628
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Print error rate for 10 tests with 5% significance
error_rate = 1 - (.95**(10))
print(error_rate)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;0.4012630607616213
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;bonferroni-correction&#34;&gt;Bonferroni correction&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s implement multiple hypothesis tests using the Bonferroni correction approach that we discussed in the slides. You&amp;rsquo;ll use the imported &lt;code&gt;multipletests()&lt;/code&gt; function in order to achieve this.&lt;/p&gt;
&lt;p&gt;Use a single-test significance level of .05 and observe how the Bonferroni correction affects our sample list of p-values already created.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from statsmodels.sandbox.stats.multicomp import multipletests
pvals = [.01, .05, .10, .50, .99]

# Create a list of the adjusted p-values
p_adjusted = multipletests(pvals, alpha=0.05, method=&#39;bonferroni&#39;)

# Print the resulting conclusions
print(p_adjusted[0])

# Print the adjusted p-values themselves 
print(p_adjusted[1])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[ True False False False False]
[0.05 0.25 0.5  1.   1.  ]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, the Bonferroni correction did it&amp;rsquo;s job and corrected the family-wise error rate for our 5 hypothesis test results. In the end, only one of the tests remained signficant. There are other methods to do tjhis test:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sidak correction&lt;/li&gt;
&lt;li&gt;Step-based procedures&lt;/li&gt;
&lt;li&gt;Tukey’s procedure&lt;/li&gt;
&lt;li&gt;Dunnet’s correction&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Perform a t-test</title>
      <link>http://othrif.github.io/technical_note/math/stats/ttest/</link>
      <pubDate>Sun, 12 Apr 2020 14:41:32 +0200</pubDate>
      <guid>http://othrif.github.io/technical_note/math/stats/ttest/</guid>
      <description>&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd
laptops = pd.read_csv(&#39;laptops.csv&#39; , encoding=&#39;latin-1&#39;, index_col=0) # added encoding because of errors
laptops = laptops.loc[laptops[&#39;Company&#39;].isin([&#39;Asus&#39;, &#39;Toshiba&#39;])]
laptops = laptops[[&#39;Company&#39;,&#39;Price_euros&#39;]]
laptops.columns = [&#39;Company&#39;, &#39;Price&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Display the mean price for each group
prices = laptops.groupby(&#39;Company&#39;).mean()
print(prices)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;               Price
Company             
Asus     1104.169367
Toshiba  1267.812500
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Assign the prices of each group
asus = laptops[laptops[&#39;Company&#39;] == &#39;Asus&#39;][&#39;Price&#39;]
toshiba = laptops[laptops[&#39;Company&#39;] == &#39;Toshiba&#39;][&#39;Price&#39;]

# Run the t-test
from scipy.stats import ttest_ind
tstat, pval = ttest_ind(asus, toshiba)
print(&#39;{0:0.3f}&#39;.format(pval))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;0.133
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a p-value of .133, we cannot reject the null hypothesis! There&amp;rsquo;s not enough evidence here to conclude that Toshiba laptops are significantly more expensive than Asus. With that being said, .133 is fairly close to reasonable significance so we may want to run another test or examine this further.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Perform a z-test</title>
      <link>http://othrif.github.io/technical_note/math/stats/ztest/</link>
      <pubDate>Sun, 12 Apr 2020 14:41:32 +0200</pubDate>
      <guid>http://othrif.github.io/technical_note/math/stats/ztest/</guid>
      <description>&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from statsmodels.stats.proportion import proportions_ztest
count = 5
nobs = 83
value = .05
stat, pval = proportions_ztest(count, nobs, value)
print(f&#39;p-value={pval:0.3f}, sig={stat:0.3f} sigma&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;p-value=0.695, sig=0.392 sigma
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
from statsmodels.stats.proportion import proportions_ztest
count = np.array([5, 12])
nobs = np.array([83, 99])
stat, pval = proportions_ztest(count, nobs)
print(f&#39;p-value={pval:0.3f}, sig={stat:0.3f} sigma&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;p-value=0.159, sig=-1.408 sigma
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;example&#34;&gt;Example&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd
results = pd.read_csv(&#39;ab_data.csv&#39; , encoding=&#39;latin-1&#39;, index_col=0) # added encoding because of errors
results = results[[&#39;group&#39;,&#39;converted&#39;]]
results.columns = [&#39;Group&#39;,&#39;Converted&#39;]
# Assign and print the conversion rate for each group
conv_rates = results.groupby(&#39;Group&#39;).mean()
print(conv_rates)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;           Converted
Group               
control     0.120399
treatment   0.118920
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Assign the number of conversions and total trials
num_control = results[results[&#39;Group&#39;] == &#39;control&#39;][&#39;Converted&#39;].sum()
total_control = len(results[results[&#39;Group&#39;] == &#39;control&#39;])

# Assign the number of conversions and total trials
num_treat = results[results[&#39;Group&#39;] == &#39;treatment&#39;][&#39;Converted&#39;].sum()
total_treat = len(results[results[&#39;Group&#39;] == &#39;treatment&#39;])

import numpy as np
from statsmodels.stats.proportion import proportions_ztest
count = np.array([num_treat, num_control]) 
nobs = np.array([total_treat, total_control])

# Run the z-test and print the result 
stat, pval = proportions_ztest(count, nobs, alternative=&amp;quot;larger&amp;quot;)
print(f&#39;p-value={pval:0.3f}, sig={stat:0.3f} sigma&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;p-value=0.892, sig=-1.237 sigma
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;p-value &amp;gt; 0.05, cannot reject the null hypothesis&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
